from pathlib import Path
import datetime
import urllib.parse

ROOT = Path(__file__).parent
DOCS = ROOT / "docs"
TEMPLATE = ROOT / "template.html"
KEYWORDS = ROOT / "keywords.txt"

# üîë Amazon affiliate tag-ed:
AMAZON_TAG = "akciosbot21-20"

# GitHub Pages alap URL (SEO-hoz haszn√°ljuk, maradhat √≠gy)
SITE_BASE = "https://arvamiklos21-debug.github.io/akcios-bot"

def load_template() -> str:
    return TEMPLATE.read_text(encoding="utf-8")

def load_keywords() -> list[str]:
    return [k.strip() for k in KEYWORDS.read_text(encoding="utf-8").splitlines() if k.strip()]

def amazon_search_url(keyword: str) -> str:
    # https://www.amazon.com/s?k=<kulcssz√≥>&tag=<tag>
    q = {"k": keyword}
    base = "https://www.amazon.com/s?" + urllib.parse.urlencode(q)
    return f"{base}&tag={AMAZON_TAG}" if AMAZON_TAG else base

def render_page(tpl: str, kw: str) -> str:
    # A template az {{amazon_url}} hely√©re kapja a tagelt keres≈ëlinket
    return (tpl
            .replace("{{title}}", f"Akci√≥s {kw} ‚Äì aj√°nlatok")
            .replace("{{keyword}}", kw)
            .replace("{{date}}", datetime.datetime.now().strftime("%Y.%m.%d."))
            .replace("{{amazon_url}}", amazon_search_url(kw))
           )

def main():
    DOCS.mkdir(exist_ok=True)
    tpl = load_template()
    keywords = load_keywords()

    links = []
    for kw in keywords:
        filename = kw.replace(" ", "_").lower() + ".html"
        (DOCS / filename).write_text(render_page(tpl, kw), encoding="utf-8")
        links.append(f'<li><a href="{filename}">{kw}</a></li>')

    index = f"""<!doctype html><html lang="hu"><meta charset="utf-8">
<title>Akci√≥s kulcsszavak</title>
<body>
<h1>Akci√≥s kulcsszavak</h1>
<ol>{''.join(links)}</ol>
<p>Friss√≠tve: {datetime.datetime.now().strftime('%Y.%m.%d.')}</p>
</body></html>"""
    (DOCS / "index.html").write_text(index, encoding="utf-8")
    print(f"‚úÖ {len(keywords)} oldal gener√°lva a /docs mapp√°ba. Tag: {AMAZON_TAG}")

if __name__ == "__main__":
    main()
